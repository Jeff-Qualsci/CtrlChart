---
title: "Control Charting"
author: "Jeffrey Weidner"
format: 
  html: 
    toc: true
    toc-depth: 3
execute:
  echo: false
  messages:  false
  warning: false
  error: false
bibliography: references.bib
editor: visual
number-sections: true
---

## Introduction

```{r}
#| label: setup
#| include: false

library(patchwork)
library(gt)
library(gtExtras)

set.seed(9031962) # for reproducibility

source('R/FunCtrlCht.R')
```

Control charts were originally developed by Walter Shewhart [@shewhart1926] at Bell Labs as a tool to monitor the quality of a process over time. They are commonly used in many fields to both document quality and identify potential problems before they become significant. Control charts analyze a measurement of a process characteristic made repeatedly over time. If the process is reproducible, then these measurements should show only normal random variation within an acceptable range. Additionally, the variation between different measurement samples should also be random and normally distributed around the true variation in the process. When both of these conditions are met, the process is said to be **in control**. Control charts may also provide signals of potential issues which can be addressed before they become serious enough to cause problems.

Before moving an assay into routine operation, it is important to have some initial measurement of its inherent variability, such as the [replicate-experiment]{.underline} [@iversen2012] to demonstrate reproducibility across 2 runs.

This tool focuses on the use of control charts to monitor assay performance in a biological laboratory using potency of a reference compound as the standard measurement of process performance. Data from these assays may be generated across extended periods of time (months to years) and it's important to document that the data collected across the lifetime of an assay is consistent and the data for non-reference compounds should be comparable across the lifetime of the assay.

## Control Chart Basics

Control charts attempt to distinguish between two types of variation, **common cause** and **for cause** variation. **Common cause** variation is simply the normal random variation for which no cause can be assigned. While, as the name would suggest, **for cause** variation suggests that there may be specific cause(s) contributing to the overall observed variability. For example, a validated bioassay should be robust to small changes for factors such as cell number, reagent composition, lab environment, etc. but at some point these differences may become large enough to significantly impact the results from the assay. ***Note: The appearance of for cause variation does not identify the nature of the cause(s). Investigation is required to identify the root cause(s) of the unexpected variation.***

Control charting uses the concept of runs to help distinguish between these two types of variability. A run can be defined as a group of process iterations for which all the known or suspected sources of variability are assumed to be consistent. In the laboratory a run can often be equated with a single experiment where working reagents/cells are prepared, no instrumentation drifts/failures are expected, and so on. It's expected that there may be small differences between experiments in the preparation of the working materials for any given experiment and do not generally impact comparison of data between experiments, so the data from either a single plate experiment or a multi-plate experiment are aggregated into a single run. It is this **within run** variability that is used to estimate the control limits for the data. However significant changes in any of many variables would be expected to have an impact on the measurement that is being monitored (e.g. a change in substrate concentration or an incubator not functioning as expected). The measurements for these runs would be expected to be different and would be flagged because of **for cause** differences. Those runs would then be considered to be out of control.

While there are different types of control charts, depending on the measurement type (continuous or attribute), this chapter will focus on potency measurements from biological assays, so control charts for a continuous variable [@guthrie] must be used.

In control charting, each new run is evaluated as a sample of the population of all the available data (current run and all previous runs). Therefore, according to the central limit theorem, the statistics for each sample are an estimate of the overall population statistics and are themselves normally distributed around the true statistics for the population. Control limits are then determined based on the normal distribution of the sample statistics (mean and standard deviation). The standard practice in control charting is to use p \< 0.01 to set the upper and lower control limits, to minimize false positives. If the data falls within these limits, then the process is said to be "in control" and is consistent with the expected variability. For simplicity, this discussion assumes that the sample size (n) is large enough (n \> 20) that no statistical adjustments are needed due to small sample size. In practice, run size may be smaller than this and the details of the calculations for these smaller runs are well documented [@guthrie].

The data in control charts is always plotted in sequential order of the runs with the run identifier on the x-axis and the run statistic on the y-axis. While the value of the run identifier is not important to the analysis, it is strongly recommended that it is either a date or an integer value. This allows the runs to be sorted and ensure that the runs are in sequential order. This allows for additional tests of the data that can serve as a signal before the run values fall outside of the control limits. For example, there should be a 50% probability that any run will have a higher value than the mean for all of the runs, but the probability of having 8 consecutive runs with each run above (or below) the population mean is p = 0.0039 and should set an "out of control" signal to investigate for a cause.

Standard statistical notation will be used to distinguish between population statistics ($mean = \mu \text{ or standard deviation} = \sigma$) and their sample counterparts ($\bar{X}$ or s).

Control charts for continuous data use the within run variability (sdwi) to estimate the common cause variability for the population and calculate the control limits. The primary data chart used is the $\overline{X}$ Chart, which shows the run means ($\overline{X}$) and reference lines for the population mean (CL) and the upper and lower control limits (UCL, LCL) which are calculated as shown: $$CL = mean(\overline{X})$$$$Control Limits = CL \pm 3(\sigma_{wi})$$

There are two charts used for control charting of continuous data. Both charts first summarize the data within individual runs and then plot the summarized values in order to evaluate the individual runs in the context of all the available data to identify possible outliers or trends. The first plot (Xbar chart) examines the consistency of those measurements between different runs, while the second plot ( S chart) is used to evaluate the within run variability of all the available runs. Both charts should be considered together to fully interpret the analysis.

```{r}
#| label: fig-basicXbar
#| fig-cap: A typical Xbar chart.

# Generate data for basic control charting

runId <- c(1:30)

Data <- vector('list', length = length(runId))

for (i in seq_along(runId)) {
  Reps <- 20  
  Data[[i]] <- rnorm(n = Reps, mean = 100, sd = 10)
}

basicRunData <- tibble(runId, Data) %>% 
  unnest(Data)

XbarChartData <- as_tibble(qic(x = basicRunData$runId, y = basicRunData$Data, chart = 'xbar', return.data = TRUE)) %>%
  qic_extract()

 XbarCht <-  ctrl_cht(XbarChartData)
 
 XbarCht
```

@fig-basicXbar is an example of an Xbar chart for a well controlled process. This chart is intended to emphasize the variability between runs, so it is scaled to include all of the run data points and the control limits, but may not include 0 on the y-axis. The data points represent the mean of all of the measurements within each run, while the center line is the mean of within run means. The control limits are calculated as described above and represent a 99% CI for the run summarized measurement values, based on the within run standard deviation (sd). These control limits will change as the number of runs in the charts increases, especially when the number of replicates in a run is small. There should be at least 6 runs before control charts are used to make decisions about any run, but it is recommended that control charting should be initiated as soon as it becomes apparent that the assay will be used repeatedly. Data points that fall outside of these control limits indicate runs that might be considered outliers and should be investigated to determine the cause of the anomaly. However, no changes should be made to a validated assay until a cause has been determined. The potential outlier, especially if it is a single run, may simply be random variability that will regress back towards the mean in the next run.

```{r}
#| label: fig-basicSChart
#| fig-cap: A typical S chart.

SChartData <- as_tibble(qic(x = basicRunData$runId, y = basicRunData$Data, chart = 's', return.data = TRUE)) %>%
  qic_extract()

SChart <- ctrl_cht(SChartData)

SChart <- SChart +
  labs(y = 'Std. Dev.')

SChart
```

An assessment of the within run variability using either the range (R chart) or standard deviation (S chart) values within each run can also be done. These variability charts include data points for the statistic as well as a center line and control limits. @fig-basicSChart is an example of an S chart from the same data used in @fig-basicXbar. While similar to the Xbar chart, it should be noted that the Lower Control Limit will never be \< 0, since these statistics are always positive numbers.

The variability chart should always be evaluated in conjunction with the data chart. For example, if there is a single run that appears out of control in the data chart and the same run shows greater than normal variability within that run, then it's likely that might be associated with just a few of the replicates that are very different from the mean.

Flags from either the data chart or the variability chart are an indication that the assay is out of control and the assay should be investigated to determine the primary cause(s) for the discrepancy. No changes should be made to the protocol unless there is an obvious observable cause (e.g a liquid handling issue that was observed during the experiment). If the error is just extreme random noise, then the data should regress toward the mean without any intervention. If a root cause is identified and changes are made to the protocol, the new protocol may need to be revalidated with a larger set of reference compounds using the [Replicate-Experiment](https://agm.ncats.nih.gov/app/) [@beck2004], to ensure that there are no systematic shifts in the data.

## Reference compound(s)

A reference compound refers to a molecule which is tested in every experimental run of an assay. This compound may be tested once per run, on every plate in a run, or on multiple plates in a run, depending on the characteristics of the assay and its sample capacity. A reference compound should be prepared and used in the assay as if it were any of the test compounds. It should exhibit a full sigmoidal dose response curve (well defined top, bottom, and AC~50~) within the dynamic range of the assay, for the most reproducible potency determinations. If a single reference compound is used, it is also recommended that its potency is near the lower limit of the current potency range, since the potency of test compounds tends to improve over time. Finally, there should be an ample supply of the reference compound so that it can be used over a large number of runs.

While a single reference compound is sufficient, many assays use multiple reference compounds. When multiple reference compounds are used, they should have different potencies and ideally be in different chemical classes. In addition to improved quality control, multiple reference compounds may identify issues specific to a chemical class and allow for a transition of reference compounds over time as the SAR evolves and the potency range of the assay may need to change.

If multiple reference compounds are used, then a separate control chart should be kept for each compound. If a change in reference compounds is anticipated, then the new reference compound should be run in parallel with the existing reference compound for at least 6 runs.

it is also important to remember that control charts only report the behavior of the reference compound and should not be a substitute for examining the curves for every sample tested before publishing the results or using them for additional analysis.

## Potency Control Charts (AGM Webtool)

Control charting the potency of reference compound(s) is a simple way to document that an assay is providing consistent data over an extended period of time. Any potency measurement can be used (e.g. AC~50~, K~i~, ED~80~, ...). However it is important to remember that potency values show a log-normal distribution [@elassaiss-schaap2020]. Therefore, as with the replicate-experiment [@beck2004], the data must be transformed to their log values for the statistical analysis. The statistics can then be transformed back to the linear scale for graphing and will appear to be normally distributed, if the y-axis is log scaled. It should be noted that the transformation of standard deviations determined on the log transformed data become fold-standard deviations when transformed back to the linear scale. \[see previous comment about linking to replicate experiment explanation\].

Since most experiments do not usually have enough replicates within the run to provide a good estimate of the population variability, adjustments must be made for the sample size within each run [@guthrie]. These adjustments use a factor, c~4~, whose value is determined by the number of replicates within each run as shown: $$\sigma_{wi} = \overline{sd_{wi}}\sqrt{1 - c^2_4}$$

When there is only a single replicate in a run, it is not possible to calculate a within run sd, so the moving range, MR, is used instead. The MR is simply the difference in the data between the current run and the previous run. These MR values are then used for the calculation of the control limits in both the data and variability graphs.

The webtool will generate different reports depending upon whether within run replicates are present (Replicates report) or not (Individuals report).

Reference compounds may be run once per run, on every plate in the run, or somewhere in between. The ideal case is to have a reference compound on every assay plate. This allows the data for the reference compound to be used to help pass or fail individual plates within a run and will provide the most consistent view of the assay process over time. However there may be circumstances where this is not feasible and a reference compound is limited to once per experiment.

The [AGM Control Charting web tool](https://agm.ncats.nih.gov/app/) does all of this for you and creates the appropriate graphs for the data set submitted. In order to load data, the webtool requires a Run ID for each run and the potency for each replicate of the reference compound in the run. It is recommended that the experiment date be used as the Run ID since this allows the runs to be sorted to ensure that they are sequential. The data should be in a .csv file with columns for "Run ID" and "Data" for each replicate. The following examples show how the tool treats the data based on the number of replicates in the data. All examples assume that the assay MSR is 3.0 and the reference compound potency is 50. **Note the analysis is independent of units, so the data is displayed in the same units as the submitted data without explicit units.**

Once the data has been uploaded to the webtool, it will calculate the number of replicates in each run and determine the appropriate analyses to run as follows:

1.  If all of the runs contain 2 or more replicates, generate a Replicates report.
2.  If most of the runs are single replicates, then generate an Individuals report using the first replicate in every run.
3.  If \< 50% of the runs are single replicates, then generate both reports.

### Constant Replicate Number (Replicates Report) {#sec-cReps}

The first example may be less common in practice, but is the simplest to interpret, because all of the runs contain the same number of replicates (n = 6), so the c~4~ factor is the same for each run and the control limits are simple horizontal lines representing the 99% Confidence Interval.

```{r}
#| label: tbl-cReps
#| tbl-cap: Constant Reps Run Data

cRepsData <- read_csv("TestData/DocData/cRepsData.csv", col_types = c("D", "d"))

cRepsHead <- cRepsData %>% 
  slice_head(n = 10) %>% 
  gt() %>% 
  tab_header(title = 'Constant Replicates Data')

cRepsHead

```

@tbl-cReps shows the first 10 lines of the input data where dates are used to identify the runs. The entire data set consists of 40 runs with 6 replicates of the reference compound in each run.

![Xbar chart of the constant replicate data.](Reports/cRepsData_2025-07-07%2020_33_11.123606/cRepsData_XbrFig_2025-07-07%2020_31_32.967119.png){#fig-cRepsXbarChart}

@fig-cRepsXbarChart shows the Xbar chart of the run date. The data points represent the geometric mean of the reference compound replicates. The center line is the grand mean of all of the run means and represents the true potency of the reference compound. The other two lines are the upper and lower control limits. It is important to note that the y-axis is displaying the data in the original linear scale, but with logarithmic spacing, so that the data appear to be evenly distributed across the graph. There is a single point that falls just below the lower control limit, but the data regress back toward the mean in the next run, strongly suggesting that this was a random event without a specific cause that needs to be addressed. A more detailed discussion of this outlier can be found in @sec-cRepsOutlier.

```{r}
#| label: tbl-cRepsXbarStats
#| tbl-cap: Constant Reps Xbar Statistics

cRepsXbarStatsHead <- read_csv("Reports/cRepsData_2025-07-07 20_33_11.123606/cRepsData_XbarChartData_tbl.csv") %>%
  filter(between(Run, as.Date('2023-05-01'), as.Date('2023-07-15'))) %>% 
  mutate(n = as.character(n)) %>%
  gt() %>%
  gt_highlight_rows(rows = 3, font_weight = "normal") %>%
  fmt_number(n_sigfig = 3) %>% 
  tab_header(title = 'Constant Replicates Xbar Chart Data')

cRepsXbarStatsHead
```

A closer look at the statistics table for the Xbar chart, @tbl-cRepsXbarStats, shows the details around the flagged run. The TRUE value in the sigma.signal column indicates a data point that falls outside of the control limits in the chart for the 2023-05-21 run. The values for the CL (50.04), LCL (31.80), and UCL (78.74) also illustrate why the y-axis uses logarithmic scaling since the confidence interval would appear asymmetric if linear scaling were used.

![S chart of the constant replicate data.](Reports/cRepsData_2025-07-07%2020_33_11.123606/cRepsData_SchFig_2025-07-07%2020_31_32.967963.png){#fig-cRepsSchart}

The within run variability is shown in @fig-cRepsSchart. The transformation back to the linear scale converts the y-axis to Fold Std. Dev. and that axis is also log scaled, similar to the Xbar chart. The center line is the transformed mean of run standard deviations (sd~*wi*~*)*. The upper Control Limit is determined by the variability in the within run standard deviations (99% confidence limit), while the Lower Control Limit is 1 which corresponds to a standard deviation of 0. There are a few, short ( n \< 6 runs) trends, but nothing sufficient to set the run.signal flag.

```{r}
#| label: tbl-cRepsSchartStats
#| tbl-cap: Constant Reps Schart Statistics

cRepsSchartStatsHead <- read_csv("Reports/cRepsData_2025-07-07 20_33_11.123606/cRepsData_SChartData_tbl.csv") %>%
  filter(between(Run, as.Date('2023-05-01'), as.Date('2023-07-15'))) %>% 
  mutate(n = as.character(n)) %>%
  gt() %>% 
   gt_highlight_rows(rows = 3, font_weight = "normal") %>%
  fmt_number(n_sigfig = 3) %>% 
  tab_header(title = 'Constant Replicates S Chart Data')

cRepsSchartStatsHead
```

The statistics table for the S chart from the same region as the flagged run in the Xbar chart confirm this, as shown in @tbl-cRepsSchartStats.

The web tool also provides a plot of the MSR values over time. While this is not a formal control chart, it can be useful in understanding the performance of an assay and how the variability can change over time. Unlike the control charts, the MSR values are calculated based on the variability determined for all the reference compound potency measurements within a range of runs, so this variability includes both within run and between run causes for variability. A minimum of 6 runs is required to calculate the MSR, so this chart will not be generated until the data set contains at least 6 runs.

The tool calculates two different values for the MSR. The cumulative MSR uses all of the data up to and including a given run. Over time this value will become less sensitive to assay changes, but should converge on the true MSR for the reference compound. The other MSR is calculated using the data from the current run as well as the previous 5 runs. This moving MSR will be more variable, but it is also more sensitive to the short-term performance of the assay.

![MSR chart of the constant replicate data.](Reports/cRepsData_2025-07-07%2020_33_11.123606/cRepsData_MSRFig_2025-07-07%2020_31_32.968709.png){#fig-cRepsMSRChart}

@fig-cRepsMSRChart shows the MSR chart for the constant replicate data. Because this is not a control chart, there are no formal statistical criteria to identify potential problems.

```{r}
#| label: tbl-cRepsMSRData
#| tbl-cap: Constant Reps MSR Data

cRepsMSRHead <- read_csv("Reports/cRepsData_2025-07-07 20_33_11.123606/cRepsData_MSRData_tbl.csv") %>% 
  slice_head(n = 10) %>% 
  gt() %>% 
  tab_header(title = 'Constant Replicates MSR Data')

cRepsMSRHead
```

As with the other charts, the table of all the run values is also available as shown in @tbl-cRepsMSRData.

See the case study on Control Charting in Real Time @sec-

### Single Values (Individuals Report)

One common approach is to test the reference compound(s) just once in each run. While this may be driven by assay constraints such as cost or capacity, it presents 2 challenges for control charting. The first is how to estimate the within run variability from a single measurement. Additionally, if there are multiple plates in a run, the reference compound can not be used as a criterion to pass or fail individual plates.

The range (R) of the data within a run is often used in control charting to estimate the within run standard deviation (sd~*wi*~) using the mean range ($\bar{R}$) [@guthrie] where:

$$
sd_\mathit{wi} = \frac{\bar{R}}{d_2}
$$

Since a single value has no range, the moving range (MR) is calculated using the data values from the current and previous runs:

$$
MR = |x_n - x_{n-1}|
$$

While the value of d~2~ is dependent upon the size of the data set, for n = 2, the value of d~2~ is 1.128. This can then be used to estimate sdwi and provides the information necessary to generate data and variability control charts as shown in the following example.

```{r}
#| label: tbl-sRepData
#| tbl-cap: Single Rep Run Data

sRepHead <-read_csv("TestData/DocData/sRepData.csv") %>% 
  slice_head(n = 10) %>% 
  gt() %>% 
  tab_header(title = 'Single Replicate Data')

sRepHead

```

@tbl-sRepData shows the first 10 lines of the input data. The entire data set consists of 40 runs with 1 replicate of the reference compound in each run.

![Individuals chart fo the single replicate data.](Reports/sRepData_2025-07-07%2020_46_00.062068/sRepData_IChFig_2025-07-07%2020_45_32.125561.png){#fig-sRepIChart}

The potency values for each run are shown in @fig-sRepIChart. While the data point and the mean are identical for individual data, it is referred to as an Individuals chart to distinguish it from an Xbar chart, though they are conceptually similar. The Center Line represents the mean of all the data and estimates the true potency of the reference compound, while the control limits indicate a 99% CI based on the sd~*wi*~. The y-axis uses log scale so that the distribution of the data appears normal. The note at the bottom of the figure indicates that the data is in control with no runs flagged for investigation.

```{r}
#| label: tbl-sRepIndChtStats
#| tbl-cap: Single Replicate  Individuals Chart Data

sRepIndStatsHead <- read_csv("Reports/sRepData_2025-07-07 20_46_00.062068/sRepData_IChartData_tbl.csv") %>% 
  mutate(n = as.character(n)) %>%
  slice_head(n = 10) %>% 
  gt()  %>% 
  fmt_number(n_sigfig = 3) %>% 
  tab_header(title = 'Single Replicate Individuals Chart Data')

sRepIndStatsHead
```

@tbl-sRepIndChtStats shows the corresponding statistics for each run. It is important to note that the Center Line and Control limits will change as more runs are added to the data set.

![Moving Range chart of the single replicate data.](Reports/sRepData_2025-07-07%2020_46_00.062068/sRepData_MRaFig_2025-07-07%2020_45_32.126426.png){#fig-sRepMRChart}

@fig-sRepMRChart shows the variability in the data over time. The moving range is determined from the log(potency) data and then transformed back to the linear scale as Fold Moving range, similar to the S chart in the previous section. The control limits are set similarly to the S chart with the upper Control Limit based on the variability of the moving range data and the Lower Control Limit equal to 1 (sd~*wi*~ = 0).

```{r}
#| label: tbl-sRepMRChartStats
#| tbl-cap: Single Rep MR Chart Statistics

sRepMRchartStatsHead <- read_csv("Reports/sRepData_2025-07-07 20_46_00.062068/sRepData_MChartData_tbl.csv") %>% 
  mutate(n = as.character(n)) %>%
  slice_head(n = 10) %>% 
  gt()  %>% 
  fmt_number(n_sigfig = 3) %>% 
  tab_header(title = 'Single Replicates MR Chart Data')

sRepMRchartStatsHead
```

@tbl-sRepMRChartStats shows the statistics and any associated flags for each run.

![MSR chart of the single replicate data,](Reports/sRepData_2025-07-07%2020_46_00.062068/sRepData_MSRFig_2025-07-07%2020_45_32.1286.png){#fig-sRepMSRChart}

@fig-sRepMSRChart is the graph of the cumulative and moving (last 6 runs) MSR values as described in the constant replicates section. The first several MSR values for single replicate data should be interpreted with caution, because of the small number of data points available for the calculation. This can result in MSR values that are significantly different from what would be determined from a Replicate-Experiment [@iversen2012] or Retrospective MSR Study [@haas2017]. Eventually the cumulative MSR should converge on a reasonable value as enough data is collected, though the moving MSR will always be limited to 6 data points.

```{r}
#| label: tbl-sRepMSRData
#| tbl-cap: Single Replicate MSR Data

sRepMSRHead <- read_csv("Reports/sRepData_2025-07-07 20_46_00.062068/sRepData_MSRData_tbl.csv") %>% 
  slice_head(n = 10) %>% 
  gt()  %>% 
  fmt_number(n_sigfig = 3) %>% 
  tab_header(title = ' Single Replicate MSR Data')

sRepMSRHead
```

@tbl-sRepMSRData shows the calculated MSR values for the first few runs in the MSR plot. Remember that MSRs are not calculated until at least 6 runs have occurred. The initial cumulative and moving MSR values are identical, since they are based on the same 6 data points. These MSRs are also significantly lower than the true MSR for the assay (3.0).

### Variable Replicates

If a reference compound is included on every plate tested, it's likely that the number of replicates will vary from run to run. While this might be a common situation, this will add some complexity to the control charts. Most runs (outside of HTS) will be small (\< 20 plates), so statistical factors are used to adjust for sampling bias in order to better estimate the population $\sigma_{\mathit(wi)}$. As described in the previous 2 sections, there are different factors for this estimate, depending on whether the range (d~2~) or the sd (c~4~) is being used. @tbl-cChartFact shows how these factors change with different values for n. The values for these factors of these factors increase asymptotically as n increases and will eventually converge on constants that are used for larger sample sizes.

```{r}
#| label: tbl-cChartFact
#| tbl-cap: Control Charting Factors.

n <- as.character(c(2:9))
d2 <- c(1.128, 1.693, 2.059, 2.326, 2.534, 2.704, 2.847, 2.970)
c4 <- c(0.7979, 0.8868, 0.9213, 0.9400, 0.9515, 0.9594, 0.9650, 0.9693)

ccFac <- tibble(n, d2, c4) %>% 
  gt()  %>% 
  fmt_number(n_sigfig = 4) %>% 
  tab_header(title = 'Control Charting Factors')

ccFac

```

In order to calculate the control limits, the runs are grouped by the number of replicates. The mean sd~*wi*~ for each group is then used with the corresponding c~4~ value to determine the control limits for all of the runs in the group. This provides the best estimate of the control limits for each group, but results in control limits that will change with the number of replicates in the run.

When the number of replicates is variable, the web tool will use all of the data from all of the runs with the same number of replicates to calculate the upper and lower control limits for that group of runs. The following data set illustrates the last situation with 1-6 replicates/run.

```{r}
#| label: tbl-vRepsData
#| tbl-cap: Variable Replicates Run Data

vRepsHead <- read_csv("TestData/DocData/vRepsData.csv") %>% 
  slice_head(n = 10) %>% 
  gt() %>% 
  tab_header(title = 'Variable Replicates Data')

vRepsHead

```

@tbl-vRepsData shows the first 10 lines of the input data. The entire data set consists of 40 runs with 1-6 replicates of the reference compound in each run to illustrate the impact of variable replicates.

![Xbar chart of the variable replicate data](Reports/vRepsData_2025-07-07%2020_48_00.53638/vRepsData_XbrFig_2025-07-07%2020_46_51.266025.png){#fig-vRepsXbarChart}

Whenever all or most of the runs contain replicates the web tool will create both an Xbar chart (@fig-vRepsXbarChart) and an S chart. Since these charts use all the replicate data, they should be examined first. As with the constant replicate example, the data points are the mean values for each run and the center line represents the population mean. The control limits now vary according to the number of replicates within the run. Generally as n increases, the control limits will get closer to the center line (CL). There are also gaps in the control limits for the runs with a single replicate because sdwi can not be calculated for single observations.

```{r}
#| label: tbl-vRepsXbarStats
#| tbl-cap: Variable Replicates Xbar Statistics

vRepsXbarStatsHead <- read_csv("Reports/vRepsData_2025-07-07 20_48_00.53638/vRepsData_XbarChartData_tbl.csv") %>% 
  mutate(n = as.character(n)) %>%
  slice_head(n = 10) %>% 
  gt()  %>% 
  fmt_number(n_sigfig = 3) %>% 
  tab_header(title = 'Variable Replicates Xbar Chart Data')

vRepsXbarStatsHead
```

The statistics for each run in the Xbar chart are shown in @tbl-vRepsXbarStats along with the run and signal flags. NA values in the Control Limit columns will occur when a run contains only a single value for the reference compound and the sd~wi~ can not be calculated with this method.

![S chart of the variable replicate data.](Reports/vRepsData_2025-07-07%2020_48_00.53638/vRepsData_SchFig_2025-07-07%2020_46_51.266698.png){#fig-vRepsSChart}

The S chart in @fig-vRepsSChart is conceptually similar to the S chart described in the constant replicates example. As with the Xbar chart, the control limits vary with the number of replicates in each run. There will also be missing data points for any runs with a single replicate, since there is no sd~wi~ associated with these runs.

```{r}
#| label: tbl-vRepsSchartStats
#| tbl-cap: Variable Replicates S chart Statistics

vRepsSchartStatsHead <- read_csv("Reports/vRepsData_2025-07-07 20_48_00.53638/vRepsData_SChartData_tbl.csv") %>% 
  mutate(n = as.character(n)) %>%
  slice_head(n = 10) %>% 
  gt() %>% 
  fmt_number(n_sigfig = 3) %>% 
  tab_header(title = 'Constant Replicates S Chart Data')

vRepsSchartStatsHead
```

@tbl-vRepsSchartStats shows the underlying statistics for each run. Runs with a single value for the reference compound will have NA values for the Std. Dev. and Control Limits colums, since sd~wi~ can not be calculated with this method.

While they only use the data from the first replicate of each run, Individuals and Moving Range charts are produced whenever there is at least one run with a single replicate of the reference compound. This may help to fill the gaps that appear in the Xbar and S charts. Additionally, whenever the majority of the runs have a single replicate of the reference compound, the Individual and Moving Range charts will be the only control charts generated by the web tool.

![Individuals chart of the variable replicate data.](Reports/vRepsData_2025-07-07%2020_48_00.53638/vRepsData_IChFig_2025-07-07%2020_46_51.264546.png){#fig-vRepIChart}

@fig-vRepIChart shows the Individuals chart from the same data set. The control limits are now constant values and cover a broader range than in the Xbar chart. The data points for each run also appear to be more variable than in the Xbar chart. It appears that a run in July almost reaches the upper control limit, but a comparison with @fig-vRepsXbarChart shows that the same run is well controlled with the run mean near the center line. The control limits also are reduced around this point, suggesting that the first replicate in this run was just a high value, but within the expected within run variation.

```{r}
#| label: tbl-vRepIndChtStats
#| tbl-cap: Variable replicates Individuals Chart Data

vRepIndStatsHead <- read_csv("Reports/vRepsData_2025-07-07 20_48_00.53638/vRepsData_IChartData_tbl.csv") %>% 
  slice_head(n = 10) %>% 
  mutate(n = as.character(n)) %>%
  gt() %>% 
  fmt_number(n_sigfig = 3) %>% 
  tab_header(title = 'Variable Replicates Individuals Chart Data')

vRepIndStatsHead

```

The data and statistics are shown in @tbl-vRepIndChtStats. Since this method uses only the first replicate in every run, there are no gaps in the graph or NA values in the data table.

![Moving Range chart of the variable replicates data.](Reports/vRepsData_2025-07-07%2020_48_00.53638/vRepsData_MRaFig_2025-07-07%2020_46_51.265325.png){#fig-vRepMRChart}

The Moving Range plot, @fig-vRepMRChart, provides an view of the within run variability without any gaps for the runs with singlet data.

```{r}
#| label: tbl-vRepMRChartStats
#| tbl-cap: Variable Replicates MR Chart Statistics

vRepMRchartStatsHead <- read_csv("Reports/vRepsData_2025-07-07 20_48_00.53638/vRepsData_MChartData_tbl.csv") %>%
  mutate(n = as.character(n)) %>%
  slice_head(n = 10) %>% 
  gt() %>% 
  fmt_number(n_sigfig = 3) %>%  
  tab_header(title = 'Variable Replicates MR Chart Data')

vRepMRchartStatsHead

```

@tbl-vRepMRChartStats shows the associated data and statistics for the Moving Range plot.

![MSR chart of the variable replicates data.](Reports/vRepsData_2025-07-07%2020_48_00.53638/vRepsData_MSRFig_2025-07-07%2020_46_51.267377.png){#fig-vRepsMSRChart}

The MSR plot, @fig-vRepsMSRChart, uses all the available replicate data and can be interpreted as described in the constant replicates example. Since most of the runs include replicates, it does not have the sample size issues discussed in the single replicate example.

```{r}
#| label: tbl-vRepsMSRData
#| tbl-cap: Variable Replicates MSR Data

vRepsMSRHead <- read_csv("Reports/vRepsData_2025-07-07 20_48_00.53638/vRepsData_MSRData_tbl.csv") %>%
  slice_head(n = 10) %>% 
  gt()  %>% 
  fmt_number(n_sigfig = 3) %>% 
  tab_header(title = 'Variable Replicates MSR Data')

vRepsMSRHead
```

@tbl-vRepsMSRData shows the MSR values after each run.

## Case Studies

### Establishing Control Limits

The best practice is to update the control charts for an assay after each run to determine if the experiment was successful. However, it ia important to remember that the control parameters will change with each additional run. These changes can be large over the first few runs. For this reason, control charts should not be used to pass or fail individual runs, until there are at least 6 runs of historical data to determine the control limits.

The following case study is based on the data from the Constant Replicates example @sec-cReps. Recall that this example had 6 replicates of the reference compound in each run. In order to demonstrate the impact of the number of replicates per run as well as the number of runs in the data set, the subsets of the data with 1, 2, or 3 replicates per run as well as the full set of 6 replicates are used in this case study. Control chart parameters were calculated using only the runs up the specified date, so the first data point represents the data from the first 2 runs.

```{r}
#| label: tbl-xBarTL1
#| tbl-cap: Control Chart parameters for each run date using the n =1 data.

runDates <- unique(cRepsData$Run)
runDates <- runDates[c(2:length(runDates))] # exclude the first date for timeline
chatData <- filter(cRepsData, Run <= runDates[3])
sel_cols <- c("x", "cl", "ucl", "lcl", "n.obs")
new_cols <- c(x = "Run", cl = "CL", ucl = "UCL", lcl = "LCL", n.obs = "n_Runs")

# Function to extract control chart parameters from a earlier date. -------------------------------------------
# endDate = last date for the extracted parameters
# ccData = data frame containing the control chart data
# ccType = type of control chart (e.g., "xbar", "s", "c", etc.) for qicharts2

extract_ctrlCht_params <- function(endDate, ccData, ccType) {
  ccData <- filter(ccData, Run <= endDate)

  if (nrow(ccData) < 2) {
    stop("Not enough data to extract control chart parameters.")
  }

  params <- qic(x = ccData$Run, y = log10(ccData$Data), chart = ccType, return.data = TRUE) %>%
    select(all_of(sel_cols)) %>%
    mutate(across(contains("cl"), pow10)) %>%
    summarize_all(last)

  return(params)
}

# Create subset of cRepsData with n = 1-3 for illustrating the impact of n ---------------------
cRepsFirst <- cRepsData %>% # n = 1
  group_by(Run) %>%
  summarise_all(first)

cRepsLast <- cRepsData %>%
  group_by(Run) %>%
  summarise_all(last)

cRepsMid <- anti_join(cRepsData, cRepsFirst) %>%
  anti_join(cRepsLast)

cReps2nd <- cRepsMid %>%
  group_by(Run) %>%
  summarise_all(first)

cReps2 <- cRepsFirst %>% # n = 2
  rbind(cReps2nd) %>%
  arrange(Run)

cReps3 <- cReps2 %>% # n = 3
  rbind(cRepsLast) %>%
  arrange(Run)

# xBar chart parameters for every run over time for each n = 1, 2, 3, 6 -------------------
xBarTL1 <- runDates %>% # n = 1
  map(\(x) extract_ctrlCht_params(endDate = x, ccData = cRepsFirst, ccType = "i")) %>%
  list_rbind() %>%
  rename(Run = x, CL = cl, UCL = ucl, LCL = lcl, n_Runs = n.obs)

xBarTL2 <- runDates %>% # n = 2
  map(\(x) extract_ctrlCht_params(endDate = x, ccData = cReps2, ccType = "xbar")) %>%
  list_rbind() %>%
  rename(Run = x, CL = cl, UCL = ucl, LCL = lcl, n_Runs = n.obs)

xBarTL3 <- runDates %>% # n = 3
  map(\(x) extract_ctrlCht_params(endDate = x, ccData = cReps3, ccType = "xbar")) %>%
  list_rbind() %>%
  rename(Run = x, CL = cl, UCL = ucl, LCL = lcl, n_Runs = n.obs)

xBarTL6 <- runDates %>% # n = 6
  map(\(x) extract_ctrlCht_params(endDate = x, ccData = cRepsData, ccType = "xbar")) %>%
  list_rbind() %>%
  rename(Run = x, CL = cl, UCL = ucl, LCL = lcl, n_Runs = n.obs)

xBarTL1Head <- xBarTL1 %>% 
  slice_head(n = 10) %>% 
  mutate(n_Runs = as.character(n_Runs)) %>% 
  gt()  %>% 
  fmt_number(n_sigfig = 3) %>% 
  tab_header(title = 'Individuals Chart Parameters')

xBarTL1Head
```

@tbl-xBarTL1 shows the parameters for the Individuals Chart (n =1) data. Since control charts require at least 2 runs, there are no parameters for the first run in the data set and each date represents an increasing number of total runs.

```{r}
#| label: fig-xBarTL
#| fig-cap: Control chart parameters vary with both the number of replicates and the number of runs. This includes the Center Line (CL) in blue, which is the mean Potency, and the the Control Limits (UCL and LCL) in red.

# Generate time line data frame for log_ctrl_cht() ------------------------------
tl_plot_data <- function(df) {
  dataCols <- c("CL", "LCL", "UCL")

  df <- df %>%
    pivot_longer(cols = all_of(dataCols), names_to = "Line", values_to = "Data") %>%
    mutate(Lines = if_else(Line == "CL", "Center Line", "Control Limit")) %>%
    slice_head(n = 45)
}

# Generate plot of control chart time line values. Modified from log_ctrl_cht() -----------------
tl_log_ctrl_cht <- function(plotdata) {
  plotdata <- tl_plot_data(plotdata)

  chart <- ggplot(plotdata, aes(x = Run, y = Data, group = Line, color = Lines)) +
    geom_point() +
    geom_line() +
    scale_colour_manual(values = c("Data" = "black", "Center Line" = "mediumblue", "Control Limit" = "red")) +
    scale_y_continuous(trans = "log10") +
    theme_linedraw() +
    theme(legend.position = "none")
}

# Create xBarTL figure ----------------
xBarTL1_plot <- tl_log_ctrl_cht(xBarTL1) +
  labs(
    title = "n = 1",
    y = "Potency"
  )

xBarTL2_plot <- tl_log_ctrl_cht(xBarTL2) +
  labs(
    title = "n = 2",
    y = "Potency"
  )

xBarTL3_plot <- tl_log_ctrl_cht(xBarTL3) +
  labs(
    title = "n = 3",
    y = "Potency"
  )

xBarTL6_plot <- tl_log_ctrl_cht(xBarTL6) +
  labs(
    title = "n = 6",
    y = "Potency"
  )

xBarTL_plot <- (xBarTL1_plot + xBarTL2_plot) / (xBarTL3_plot + xBarTL6_plot) +
  plot_annotation(
    title = "Measurement Chart Parameters Time Lines.", tag_levels = "A"
  )

xBarTL_plot
```

The variability in the parameters for the mean potency is shown in @fig-xBarTL, for each data set with the center line (CL) in blue and the control limits (UCL, LCL) in red. While all of the data sets show some significant differences in the control limits in the first few runs, they tend to converge to a steady state after about 6 runs. The differences between the y-axes for the different runs also illustrates the impact of increasing n on the parameter estimates.

```{r}
#| label: fig-sChartTL
#| fig-cap: Variability control chart parameters vary with both the number of replicates and the number of runs. This includes the Center Line (CL) in blue, which is the mean Potency, and the the Control Limits (UCL and LCL) in red.

# Schart parameters for every run over time for n = 1, 2, 3, 6 ----------------
sChartTL1 <- runDates %>% # n = 1
  map(\(x) extract_ctrlCht_params(endDate = x, ccData = cRepsFirst, ccType = "mr")) %>%
  list_rbind() %>%
  rename(Run = x, CL = cl, UCL = ucl, LCL = lcl, n_Runs = n.obs)

sChartTL2 <- runDates %>% # n = 2
  map(\(x) extract_ctrlCht_params(endDate = x, ccData = cReps2, ccType = "s")) %>%
  list_rbind() %>%
  rename(Run = x, CL = cl, UCL = ucl, LCL = lcl, n_Runs = n.obs)

sChartTL3 <- runDates %>% # n = 3
  map(\(x) extract_ctrlCht_params(endDate = x, ccData = cRepsData, ccType = "s")) %>%
  list_rbind() %>%
  rename(Run = x, CL = cl, UCL = ucl, LCL = lcl, n_Runs = n.obs)

sChartTL6 <- runDates %>% # n = 6
  map(\(x) extract_ctrlCht_params(endDate = x, ccData = cRepsData, ccType = "s")) %>%
  list_rbind() %>%
  rename(Run = x, CL = cl, UCL = ucl, LCL = lcl, n_Runs = n.obs)

# Create SchartTL figure ----------------
sChartTL1_plot <- tl_log_ctrl_cht(sChartTL1) +
  labs(
    title = "n = 1",
    y = "Fold MR"
  )

sChartTL2_plot <- tl_log_ctrl_cht(sChartTL2) +
  labs(
    title = "n = 2",
    y = "Fold Std. Dev."
  )

sChartTL3_plot <- tl_log_ctrl_cht(sChartTL3) +
  labs(
    title = "n = 3",
    y = "Fold Std. Dev."
  )

sChartTL6_plot <- tl_log_ctrl_cht(sChartTL6) +
  labs(
    title = "n = 6",
    y = "Fold Std. Dev."
  )

sChartTL_plot <- (sChartTL1_plot + sChartTL2_plot) / (sChartTL3_plot + sChartTL6_plot) +
  plot_annotation(
    title = "Variability Chart Parameters Time Lines.", tag_levels = "A"
  )
sChartTL_plot
```

The variability charts in @fig-sChartTL show a similar pattern with more differences in the initial runs before converging towards more consistent values in the later runs.

These plots illustrate why you should not use the control limits in the initial runs of an assay to make pass/fail decisions about those runs. Though, after sufficient data has been collected, you may recognize that an early run was out of control. Additionally, as the number of runs increases, the control limits will become less sensitive to changes in assay performance. If the assay appears to be in control, this can be mitigated by starting a new set of charts, with just the 10 most recent runs to establish updated control limits.

### Evaluating Out of Control Data (Constant Replicates Example). {#sec-cRepsOutlier}

Ideally, a new control chart should be created and reviewed as soon as possible after each run. If the data for the reference compound(s) appear to be in control (no flags in the run.signal or sigma.signal columns), then the experiment can be considered to be successful.

If the reference compound out of control, the data from the entire experiment may be suspect and further investigation is needed. It is much easier to identify potential causes while the experimental details are more readily available. If potential causes are identified (e.g. the assayer observed something unusual during the assay) they can be assessed for their impact on the whole experiment. Having a reference compound on each plate allows individual plates to be passed or failed. If there are are replicates within the run, but not on every plate, then any plates between two passing replicates are considered suspect and if there is only one instance of the reference compound in a run, then all the plates in the run are suspect.

When a cause can not be easily identified, it is important to remember that this simply might be random error and a repeat of the experiment could resolve the problem. Simply repeating the experiment, may resolve the issue. If it is not feasible to repeat the experiment with all of the test samples, then the assay should be repeated with just the reference compound(s) to confirm the problem, before making any changes to the validated protocol.

::: {#fig-outlier layout-nrow=2}

![](Reports/cRepsOutData_2025-07-07%2020_49_06.502218/cRepsOutData_XbrFig_2025-07-07%2020_48_19.233482.png)

![](Reports/cRepsOutData_2025-07-07%2020_49_06.502218/cRepsOutData_SchFig_2025-07-07%2020_48_19.234251.png)

Outlier Control charts. 
:::

@fig-outlier shows the control charts for the suspect run. Since the last data point in the Xbar chart falls just below the Lower Control Limit, the run needs to be investigated. However, the S chart shows that the variability for that run appears to fine, so it is possible that this is simply random noise.

```{r}
#| label: tbl-cRepsOutRun
#| tbl-cap: Replicate data for the suspect run.

cRepsOutRun <- read_csv("TestData/DocData/cRepsOutData.csv")

runDates <- unique(cRepsOutRun$Run)

cRepsOutRun <- cRepsOutRun %>%
  filter(Run == runDates[20]) %>% 
  gt()  %>% 
  fmt_number(n_sigfig = 3) %>% 
  tab_header(title = 'Data for 5/21/2023')

cRepsOutRun
```

The next step would be to examine the individual replicates as shown in @tbl-cRepsOutRun. Only the replicates 3 and 4 are close to the expected value of 50, while the other 4 replicates are closer to half of the expected value. At this point the individual curve fits could be examined for possible outlier data points. It is possible that there could have been an error in either the preparation of the reference compound or another reagent for this experiment or a liquid handling problem with the suspect plates. Unless the assayer observed something specific, there is no assignable cause. At this point the best thing to run the experiment again without making any changes to the protocol. In this case we know from @fig-cRepsXbarChart that the next run was fine. While the data from the other samples in these experiments is not available, if there were results for those test samples in other runs, a paired t-test or other analysis might be used to confirm if there was an issue with the run in question. For this reason, it would be important to document the suspected issues with that run, in case of further issues with any of the data generated in the experiment. It would also be recommended to rerun all of the test samples from the suspected run at some point to confirm the test results.

## Acknowledgement

The Assay Guidance Manual Webtools are supported by the Intramural Research Program of the National Center for Advancing Translational Sciences at the National Institutes of Health (ZIA TR000340).

## References
